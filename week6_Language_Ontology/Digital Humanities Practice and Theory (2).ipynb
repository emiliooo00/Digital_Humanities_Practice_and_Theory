{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6619acf0",
   "metadata": {},
   "source": [
    "## SpaCy\n",
    "\n",
    "A newer machine learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00e61d",
   "metadata": {},
   "source": [
    "Currently, Spacy does not work with versions of Python above 3.12. To work around this, you can use conda/mamba to create a new environment called `spacy` with Python version 3.12. \n",
    "\n",
    "    mamba create -n spacy python=3.12\n",
    "    mamba activate spacy\n",
    "    mamba install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5bf28-ee67-4486-9473-6988fc7fa1f7",
   "metadata": {},
   "source": [
    "The quick and easy way to run this notebook in that new environment would be to install jupyter there: `mamba install jupyter`.\n",
    "\n",
    "A more correct solution would be to run jupyter from your usual environment and but then run this notebook with the Python kernel from this new environment.  \n",
    "\n",
    "For a discussion on how to be able to switch Python kernels from different conda environments, see [this webpage](https://towardsdatascience.com/get-your-conda-environment-to-show-in-jupyter-notebooks-the-easy-way-17010b76e874).  The basic idea is that in your base environment, do `mamba install nb_conda_kernels` and then in the new environment whose kernel you want to access, do `mamba install ipykernel`.  Then restart Jupyter from your base environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810dfa3-3c1d-4a2c-9a68-b17b234cfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83752952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3565b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in nlp('boxes was having mice children swam dug'):\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carroll-alice.txt') as f:\n",
    "    alice = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ddf934",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc88daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c378b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5afdb0",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "Pulling references to concrete people, places and things in the real world out of texts is crucial to many forms of cultural analysis.\n",
    "\n",
    "But it's pretty tricky to do in the general sense (easier if you know what you are looking for).\n",
    "\n",
    "As our sample text, instead of *Alice in Wonderland*, let's use the text of Lewis Carroll's Wikipedia entry, which has a lot more references to the real world.\n",
    "\n",
    "We use Beautiful Soup to parse the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a4a26-a245-4beb-866c-57e5539504c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Educational script',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d55fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://en.wikipedia.org/wiki/Lewis_Carroll\", \n",
    "                    headers=headers)\n",
    "page_content = BeautifulSoup(page.text, \"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a3e89",
   "metadata": {},
   "source": [
    "Very messy!  We just want the text of the article.  So we look for paragraphs `<p> ... </p>` and then we extract the text within each one without any tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e816db",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for para in page_content.find_all(\"p\"):\n",
    "    para = para.text\n",
    "    text += para\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a86d18",
   "metadata": {},
   "source": [
    "Those newlines are annoying, so let's get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for para in page_content.find_all(\"p\"):\n",
    "    para = para.text\n",
    "    para = para.replace(\"\\n\", \" \")\n",
    "    text += para\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b910a5",
   "metadata": {},
   "source": [
    "That's pretty clean, except for the footnote markers (e.g. `[1]`).  Let's get rid of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = ''\n",
    "for para in page_content.find_all(\"p\"):\n",
    "    para = para.text\n",
    "    para = para.replace(\"\\n\", \" \")\n",
    "    para = re.sub(r'\\[\\d+\\]', '', para)\n",
    "    text += para\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1ed4c",
   "metadata": {},
   "source": [
    "Now we have a text, but how do we find the named entities?  A naive approach would be to look for capitalized words, but that does not work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39094712",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in text.split():\n",
    "    if re.match(r'[A-Z]', word):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carroll.txt', mode='w', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d19d92",
   "metadata": {},
   "source": [
    "## Spacy for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b53398",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(tags, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747beba",
   "metadata": {},
   "source": [
    "## Dependency parsing\n",
    "\n",
    "See [this introduction](https://universaldependencies.org/introduction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af45f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_tags = nlp('''Alice was beginning to get very tired of sitting by her sister on the\n",
    "bank, and of having nothing to do: once or twice she had peeped into the\n",
    "book her sister was reading, but it had no pictures or conversations in\n",
    "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
    "conversation?' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(alice_tags, jupyter=True, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_spans = list(tags.sents)\n",
    "displacy.render(sentence_spans, jupyter=True, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01ae28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.dep_ == 'amod':\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390de794",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    for child in token.children:\n",
    "        if child.text == 'little':\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f17a99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    for child in token.children:\n",
    "        if child.text == 'little' and token.pos_ == 'NOUN':\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910b137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjectives = ['little', 'small']\n",
    "#adjectives = ['little', 'big', 'large', 'small']\n",
    "from collections import Counter\n",
    "things = Counter()\n",
    "for token in doc:\n",
    "    for child in token.children:\n",
    "        if child.lemma_ in adjectives and token.pos_ == 'NOUN':\n",
    "            things[token.lemma_] += 1\n",
    "things.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be7386",
   "metadata": {},
   "source": [
    "## Jane Austen\n",
    "\n",
    "What are Jane Austen's favourite adjectives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# austen_resp = requests.get(\"https://www.gutenberg.org/files/31100/31100.txt\")\n",
    "austen_resp = requests.get(\"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\", \n",
    "                           headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449dee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = austen_resp.content.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen.index('It is a truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df159d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen[35886:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf78eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = austen[35886:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adab095",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4637c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "austen = re.sub(r'[\\r\\n]+', ' ', austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5bbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = re.sub(r'\\[.*?\\]+', ' ', austen, flags=re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4735b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a087a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_doc = nlp(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in austen_doc:\n",
    "    if token.dep_ == 'amod':\n",
    "        print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf165ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = Counter()\n",
    "for token in austen_doc:\n",
    "    if token.dep_ == 'amod':\n",
    "        adjectives[token.lemma_] += 1\n",
    "adjectives.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "women = Counter()\n",
    "for token in doc:\n",
    "    if token.lemma_ in ['girl', 'woman', 'wife', 'lady']:\n",
    "        for child in token.children:\n",
    "            if child.pos_ == 'ADJ':\n",
    "#                 print(child.pos_, child.lemma_)\n",
    "                women[child.lemma_] += 1\n",
    "women.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_resp = requests.get(\"https://www.gutenberg.org/files/31100/31100-0.txt\", \n",
    "                           headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = str(austen_resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb797e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = re.sub(r'\\\\r\\\\n', ' ', austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed606733",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = len(austen) + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_doc = nlp(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "women = Counter()\n",
    "for token in austen_doc:\n",
    "    if token.lemma_ in ['girl', 'woman', 'wife', 'lady', 'she', 'her']:\n",
    "        for child in token.children:\n",
    "            if child.pos_ == 'ADJ':\n",
    "#                 print(child.pos_, child.lemma_)\n",
    "                women[child.lemma_] += 1\n",
    "women.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58889d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
