{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9a7217",
   "metadata": {},
   "source": [
    "# NLP with Stanza\n",
    "\n",
    "A new machine learning library in Python from the Stanford NLP research group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b3ca5-47a4-4810-bcff-ab7832d87351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bb76d",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b453c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af8c979b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131afb11cb7b4927bf95f563d6f1b5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 22:42:38 INFO: Downloaded file to /Users/dkl0pjh/stanza_resources/resources.json\n",
      "2025-11-10 22:42:38 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-11-10 22:42:39 INFO: File exists: /Users/dkl0pjh/stanza_resources/en/default.zip\n",
      "2025-11-10 22:42:43 INFO: Finished downloading models and saved to /Users/dkl0pjh/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en') # download English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9988317d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 22:42:54 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0599c59c94549aeb099b340c62a74f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 22:42:54 INFO: Downloaded file to /Users/dkl0pjh/stanza_resources/resources.json\n",
      "2025-11-10 22:42:55 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2025-11-10 22:42:55 WARNING: GPU requested, but is not available!\n",
      "2025-11-10 22:42:55 INFO: Using device: cpu\n",
      "2025-11-10 22:42:55 INFO: Loading: tokenize\n",
      "2025-11-10 22:42:55 INFO: Loading: mwt\n",
      "2025-11-10 22:42:55 INFO: Loading: pos\n",
      "2025-11-10 22:42:57 INFO: Loading: lemma\n",
      "2025-11-10 22:42:57 INFO: Loading: constituency\n",
      "2025-11-10 22:42:58 INFO: Loading: depparse\n",
      "2025-11-10 22:42:58 INFO: Loading: sentiment\n",
      "2025-11-10 22:42:58 INFO: Loading: ner\n",
      "2025-11-10 22:43:01 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en', use_gpu=True) # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9b7fc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"boxes\",\n",
       "      \"lemma\": \"box\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NNS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 0,\n",
       "      \"end_char\": 5,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"was\",\n",
       "      \"lemma\": \"be\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"VBD\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"aux\",\n",
       "      \"start_char\": 6,\n",
       "      \"end_char\": 9,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"having\",\n",
       "      \"lemma\": \"have\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBG\",\n",
       "      \"feats\": \"Tense=Pres|VerbForm=Part\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"start_char\": 10,\n",
       "      \"end_char\": 16,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"children\",\n",
       "      \"lemma\": \"child\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NNS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"obj\",\n",
       "      \"start_char\": 17,\n",
       "      \"end_char\": 25,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 5,\n",
       "      \"text\": \"mice\",\n",
       "      \"lemma\": \"mouse\",\n",
       "      \"upos\": \"NOUN\",\n",
       "      \"xpos\": \"NNS\",\n",
       "      \"feats\": \"Number=Plur\",\n",
       "      \"head\": 6,\n",
       "      \"deprel\": \"nsubj\",\n",
       "      \"start_char\": 26,\n",
       "      \"end_char\": 30,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 6,\n",
       "      \"text\": \"swam\",\n",
       "      \"lemma\": \"swim\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBD\",\n",
       "      \"feats\": \"Mood=Ind|Person=3|Tense=Past|VerbForm=Fin\",\n",
       "      \"head\": 3,\n",
       "      \"deprel\": \"parataxis\",\n",
       "      \"start_char\": 31,\n",
       "      \"end_char\": 35,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ]\n",
       "    },\n",
       "    {\n",
       "      \"id\": 7,\n",
       "      \"text\": \"dug\",\n",
       "      \"lemma\": \"dig\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBN\",\n",
       "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
       "      \"head\": 6,\n",
       "      \"deprel\": \"xcomp\",\n",
       "      \"start_char\": 36,\n",
       "      \"end_char\": 39,\n",
       "      \"ner\": \"O\",\n",
       "      \"multi_ner\": [\n",
       "        \"O\"\n",
       "      ],\n",
       "      \"misc\": \"SpaceAfter=No\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('boxes was having children mice swam dug')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.\") # run annotation over a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd6421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b73a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01672f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carroll.txt') as f:\n",
    "    carroll = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e257d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "carroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "carroll_doc = nlp(carroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in carroll_doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "carroll_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83215dd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in carroll_doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29458fdf",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[(sent.sentiment, sent.text) for sent in carroll_doc.sentences], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e5acb",
   "metadata": {},
   "source": [
    "## Oliver Twist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647c3de-ed1f-46f1-aeeb-78e44bb5da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Educational script',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twist_resp = requests.get(\"https://www.gutenberg.org/files/730/730-0.txt\",\n",
    "                         headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7411e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twist_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twist = str(twist_resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "twist[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730992be",
   "metadata": {},
   "outputs": [],
   "source": [
    "twist_doc = nlp(twist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3208cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in twist_doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77e30d-6f6e-4b26-9d30-10a189c2a25c",
   "metadata": {},
   "source": [
    "James Joyce, \"The Dead\" from _Dubliners_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dub_resp = requests.get(\"https://www.gutenberg.org/files/2814/2814-0.txt\",\n",
    "                       headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dub_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "dub = str(dub_resp.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49921fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dub[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e38b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dub.index('THE DEAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead = dub[290819:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f59b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_doc = nlp(dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d068c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in dead_doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f142ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_places = []\n",
    "for ent in dead_doc.ents:\n",
    "    if ent.type == 'LOC' or ent.type == 'GPE':\n",
    "        print(ent.text)\n",
    "        dead_places.append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dead_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14644866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df44953",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_places2 = []\n",
    "for place in dead_places:\n",
    "    place = re.sub(r'\\s*[\\r\\n]+\\s*', ' ', place)\n",
    "    print(place)\n",
    "    dead_places2.append(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dead_places2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dead_places.txt', 'w') as f:\n",
    "    for place in set(dead_places2):\n",
    "        f.write(f\"{place}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21ad70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
