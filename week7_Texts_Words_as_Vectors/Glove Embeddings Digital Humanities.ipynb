{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d50ed4c",
   "metadata": {},
   "source": [
    "# Context-free Word Embeddings\n",
    "\n",
    "Before transformers, the state of the art in context-free embeddings was [GloVe](https://nlp.stanford.edu/projects/glove/).  You can download various sizes of embeddings from that page.\n",
    "\n",
    "You can download the code [here](https://github.com/stanfordnlp/GloVe), but it requires compilation.  There are some demo Python scripts that come with it.\n",
    "\n",
    "But we will use the embeddings directly, following [this blog](https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96530d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8145ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "glove_path = \"/Users/dkl0pjh/ML/tools/GloVe/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh {glove_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366236a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glove_path, 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "        except:\n",
    "            pass\n",
    "#             print(line)\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_keys = []\n",
    "for key in embeddings_dict.keys():\n",
    "    if embeddings_dict[key].shape[0] != 300:\n",
    "        print(key)\n",
    "        bad_keys.append(key)\n",
    "for key in bad_keys:\n",
    "    del embeddings_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_dict.keys(), \n",
    "                  key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings2(embedding):\n",
    "    return sorted(embeddings_dict.keys(), \n",
    "                  key=lambda word: spatial.distance.cosine(embeddings_dict[word], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(embeddings_dict[\"king\"])[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings2(embeddings_dict[\"king\"])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42c85b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Paris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43membeddings_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mParis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m embeddings_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m embeddings_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngland\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m target\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Paris'"
     ]
    }
   ],
   "source": [
    "target = embeddings_dict[\"Paris\"] - embeddings_dict[\"France\"] + embeddings_dict[\"England\"]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings(target)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2309ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_embeddings2(target)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8af5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analogy (words, cosine=False):\n",
    "    target = embeddings_dict[words[1]] - embeddings_dict[words[0]] + embeddings_dict[words[2]]\n",
    "    if cosine:\n",
    "        closest = find_closest_embeddings2(target)\n",
    "    else:\n",
    "        closest = find_closest_embeddings(target)\n",
    "    for w in closest:\n",
    "        if not w in words:\n",
    "            analogy = w\n",
    "            break\n",
    "    print(f\"{words[0]} is to {words[1]} as {words[2]} is to {analogy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['Paris', 'France', 'London'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['man', 'woman', 'uncle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d41fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['man', 'woman', 'doctor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['head', 'body', 'roof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd80434",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['head', 'body', 'roof'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f310e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['body', 'head', 'house'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['body', 'head', 'house'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analogy(['cold', 'ice', 'heat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddb096",
   "metadata": {},
   "source": [
    "## Plotting with t-SNE and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97c403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['man', 'woman', 'king', 'queen', 'aunt', 'uncle', 'ice', 'water', 'steam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bcb8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'man'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectors \u001b[38;5;241m=\u001b[39m [\u001b[43membeddings_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'man'"
     ]
    }
   ],
   "source": [
    "vectors = [embeddings_dict[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=3)\n",
    "vectors = [embeddings_dict[word] for word in words]\n",
    "Y = tsne.fit_transform(vectors)\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1])\n",
    "for label, x, y in zip(words, Y[:, 0], Y[:, 1]):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords=\"offset points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ef271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "Y = PCA(n_components=2).fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7726a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y[:, 0], Y[:, 1])\n",
    "for label, x, y in zip(words, Y[:, 0], Y[:, 1]):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords=\"offset points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc2002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
